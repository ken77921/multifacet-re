{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, MDS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MILESTONE\n",
    "MILESTONE_PAT_OUTDIR = '../output/run31_vbasis_nornds11_rare_l3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_maxopt_autofixed-b5-kb11/patterns'\n",
    "MILESTONE_KB_OUTDIR = '../output/run31_vbasis_nornds11_rare_l3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_maxopt_autofixed-b5-kb11/kb_rels'\n",
    "MILESTONE_TARGET_EMB = \"../models/run31_vbasis_nornds11_rare_l3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_maxopt_autofixed-b5-kb11-20200618-214714/ep50/target_emb.pt\"\n",
    "\n",
    "# BASELINE\n",
    "# BASELINE_TARGET_EMB = \"../models/run31_vbasis_nornds11_rare_l3_trans_encdrop_pt3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_maxopt_autofixed-b1-kb1-20200802-171731/ep50/target_emb.pt\"\n",
    "# BASELINE_PAT_OUTDIR = '../output/run31_vbasis_nornds11_rare_l3_trans_encdrop_pt3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_maxopt_autofixed-b1-kb1/patterns'\n",
    "# BASELINE_KB_OUTDIR = '../output/run31_vbasis_nornds11_rare_l3_trans_encdrop_pt3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_maxopt_autofixed-b1-kb1/kb_rels'\n",
    "\n",
    "# NEW BASELINE AFTER HYPERPARAM TUNING\n",
    "BASELINE_TARGET_EMB = \"../models/run31_vbasis_nornds11_rare_l3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_encdrop_pt35_maxopt_autofixed-b1-kb1-20200920-003007/ep50/target_emb.pt\"\n",
    "BASELINE_PAT_OUTDIR = '../output/run31_vbasis_nornds11_rare_l3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_encdrop_pt35_maxopt_autofixed-b1-kb1/patterns'\n",
    "BASELINE_KB_OUTDIR = '../output/run31_vbasis_nornds11_rare_l3_autosgdlrpt1_autow_pt2_tgtlr1_autoavg_preavg_encdrop_pt35_maxopt_autofixed-b1-kb1/kb_rels'\n",
    "\n",
    "KB_BASIS_PRED_FILE = 'basis_pred.npy'\n",
    "KB_EMB_FILE = 'emb.npy'\n",
    "IDX2KB_FILE = 'idx2kb_dict.pkl'\n",
    "PAT_BASIS_PRED_FILE = 'pat_basis_pred.pt'\n",
    "IDX2PAT = 'idx2pat_dict.pkl'\n",
    "ENTPAIR_NEW_VOCAB_FILE = '../data/var_basis_wo_test/entpair-new-vocab.txt'\n",
    "ENTPAIR_DICT = '../data/var_basis_wo_test/entpair_dictionary_index'\n",
    "FREEBASE_MAP = \"../data/en-freebase_wiki_cat_title_map.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(PAT_OUTDIR, KB_OUTDIR, TARGET_EMB):\n",
    "    # Read basis predictions for patterns\n",
    "    pat_basis_preds = torch.load(os.path.join(PAT_OUTDIR, PAT_BASIS_PRED_FILE), map_location='cpu')\n",
    "    print(\"Pattern basis predictions:\", pat_basis_preds.shape)\n",
    "    # Read idx2pat map\n",
    "    with open(os.path.join(PAT_OUTDIR, IDX2PAT), 'rb') as fin:\n",
    "        idx2pat = pickle.load(fin)\n",
    "    # Construct pat2idx map\n",
    "    pat2idx = {pat:i for i, pat in enumerate(idx2pat.values())}\n",
    "    print('Finished constructing pat2idx')\n",
    "    # Read basis predictions for kb relations\n",
    "    kb_basis_preds = np.load(os.path.join(KB_OUTDIR, KB_BASIS_PRED_FILE))\n",
    "    print('KB Relation basis predictions:', kb_basis_preds.shape)\n",
    "    \n",
    "#     # Read embeddings for kb relations (encoder output)\n",
    "#     kb_embs = np.load(os.path.join(KB_OUTDIR, KB_EMB_FILE))\n",
    "    \n",
    "    # Read idx2kb map\n",
    "    with open(os.path.join(KB_OUTDIR, IDX2KB_FILE), 'rb') as fin:\n",
    "        idx2kb = pickle.load(fin)\n",
    "    # Construct kb2idx map\n",
    "    kb2idx = {kb + ' <eos>':i for i, kb in enumerate(idx2kb.values())}\n",
    "    print(\"Finished constructing kb2idx\")\n",
    "    # Read entity pair vocab\n",
    "    entpair_vocab_map = {}\n",
    "    with open(ENTPAIR_NEW_VOCAB_FILE, \"r\") as fin:    \n",
    "        for line in fin:\n",
    "            line = line.rstrip()\n",
    "            index = line.find(\":\")\n",
    "            entpair_vocab_map[line[:index]] = line[index+1:]\n",
    "    print(\"Finished reading entity pair vocab\")\n",
    "#     # Read entity pair frequency map\n",
    "#     target_idx2word_freq = []\n",
    "#     with open(ENTPAIR_DICT, \"r\") as f_in:    \n",
    "#         for i, line in enumerate(f_in):\n",
    "#             fields = line.rstrip().split('\\t')\n",
    "#             if len(fields) == 3:\n",
    "#                 assert len(target_idx2word_freq) == int(fields[2])\n",
    "#                 target_idx2word_freq.append([fields[0],int(fields[1])])\n",
    "    \n",
    "    # Read freebase code to entity map\n",
    "    freebase_map = {}\n",
    "    with open(FREEBASE_MAP, 'r') as fin:\n",
    "        for line in fin:\n",
    "            parts = line.strip().split('\\t')\n",
    "            freebase_map[parts[1]] = parts[0]        \n",
    "            assert len(parts) == 2, \"Got length: {}\".format(len(parts))    \n",
    "    freebase_map_rev = {v:k for k, v in freebase_map.items()}\n",
    "    print(\"Finished reading freebase code to entity map\")\n",
    "    \n",
    "    # Construct entity pair to idx map\n",
    "    target2idx = {target: int(idx[2:]) for idx, target in entpair_vocab_map.items()}\n",
    "    \n",
    "    # Read top 3 closest entity pairs for patterns/kb rels from json\n",
    "    # json constructed manually\n",
    "    def get_target_emb(target):\n",
    "        return target_embs[target2idx[target]]\n",
    "    with open(\"../output/closest_pairs.json\", \"r\") as fin:\n",
    "        closest_pairs = json.load(fin)\n",
    "\n",
    "    def parse_targets(targets):\n",
    "        targets_str = targets[targets.find(':')+1:].strip()    \n",
    "        return list(filter(lambda s: s != \"\", re.split(r'\\s*0\\.\\d+\\s*', targets_str)))\n",
    "\n",
    "    for run, pat2targets in closest_pairs.items():\n",
    "        for pat, basis_list in pat2targets.items():\n",
    "            for basis, targets in enumerate(basis_list):\n",
    "                target_list = parse_targets(targets)\n",
    "                target_idx_list = []\n",
    "                for target in target_list:\n",
    "                    target = \"\\t\".join(list(map(lambda entity: freebase_map_rev.get(entity, entity), target.split(\"\\t\"))))\n",
    "                    target_idx_list.append(target2idx.get(target, -1))\n",
    "                basis_list[basis] = list(zip(target_idx_list, target_list))\n",
    "    # pprint.pprint(closest_pairs)\n",
    "    target_embs = torch.load(TARGET_EMB, map_location='cpu')\n",
    "    print(\"Targets:\", target_embs.shape)\n",
    "   \n",
    "    return { \n",
    "        'pat_basis_preds': pat_basis_preds, \n",
    "        'pat2idx': pat2idx, \n",
    "        'kb_basis_preds': kb_basis_preds, \n",
    "        'kb2idx': kb2idx, \n",
    "        'closest_pairs': closest_pairs, \n",
    "        'target_embs': target_embs,\n",
    "        'target2idx': target2idx\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern basis predictions: torch.Size([1261610, 11, 100])\n",
      "Finished constructing pat2idx\n",
      "KB Relation basis predictions: (41, 11, 100)\n",
      "Finished constructing kb2idx\n",
      "Finished reading entity pair vocab\n",
      "Finished reading freebase code to entity map\n",
      "Targets: torch.Size([549761, 100])\n"
     ]
    }
   ],
   "source": [
    "milestone_data = prepare_data(MILESTONE_PAT_OUTDIR, MILESTONE_KB_OUTDIR, MILESTONE_TARGET_EMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern basis predictions: torch.Size([1261610, 1, 100])\n",
      "Finished constructing pat2idx\n",
      "KB Relation basis predictions: (41, 1, 100)\n",
      "Finished constructing kb2idx\n",
      "Finished reading entity pair vocab\n",
      "Finished reading freebase code to entity map\n",
      "Targets: torch.Size([549761, 100])\n"
     ]
    }
   ],
   "source": [
    "baseline_data = prepare_data(BASELINE_PAT_OUTDIR, BASELINE_KB_OUTDIR, BASELINE_TARGET_EMB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headquarter example for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = ['$ARG1 headoffice in $ARG2 <eos>', \\\n",
    "            '$ARG1 headqarters in $ARG2 <eos>', \\\n",
    "            'org:city_of_headquarters <eos>', \\\n",
    "            '$ARG1 is now at $ARG2 <eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_embs(patterns, run, data, use_random=False, std=0.01, seed=20):\n",
    "    np.random.seed(seed)\n",
    "    pat_basis_preds = data['pat_basis_preds']\n",
    "    pat2idx = data['pat2idx']\n",
    "    kb_basis_preds = data['kb_basis_preds']\n",
    "    kb2idx = data['kb2idx']\n",
    "    closest_pairs = data['closest_pairs']\n",
    "    target_embs = data['target_embs']\n",
    "    \n",
    "    pattern_pred_embs = np.concatenate([pat_basis_preds[pat2idx[pat]].numpy() \\\n",
    "                                        if pat in pat2idx else kb_basis_preds[kb2idx[pat]] \\\n",
    "                                        for pat in patterns], axis=0)\n",
    "    if use_random:\n",
    "        pattern_pred_embs += np.random.randn(*pattern_pred_embs.shape)*std\n",
    "    print(\"Basis predictions:\", pattern_pred_embs.shape)\n",
    "    target_embs_for_pats = np.concatenate([target_embs[entpair[0]].detach().cpu().numpy().reshape(1, -1) \\\n",
    "                                           for i in range(len(patterns)) \\\n",
    "                                           for basis_list in closest_pairs[run][patterns[i]] \\\n",
    "                                           for entpair in basis_list], axis=0)\n",
    "    target_embs_for_pats_uniq, target_embs_for_pats_idx = np.unique(target_embs_for_pats, \\\n",
    "                                                                    return_index=True, \\\n",
    "                                                                    axis=0)\n",
    "    print(\"Unique entity pairs:\", target_embs_for_pats_uniq.shape)\n",
    "    target_embs_for_pats_labels = [entpair[1] for i in range(len(patterns)) \\\n",
    "                                   for basis_list in closest_pairs[run][patterns[i]] \\\n",
    "                                   for entpair in basis_list]\n",
    "    target_embs_for_pats_labels_uniq = np.take(target_embs_for_pats_labels, target_embs_for_pats_idx)   \n",
    "    \n",
    "    combined = np.concatenate([pattern_pred_embs, target_embs_for_pats_uniq], axis=0)\n",
    "    print(\"Combined:\", combined.shape)\n",
    "    reduced_tsne = TSNE(n_components=2, perplexity=25).fit_transform(combined)\n",
    "    reduced_mds = MDS(n_components=2, random_state=seed).fit_transform(combined)\n",
    "    print(\"Reduced:\", 'tsne-:', reduced_tsne.shape, 'mds-:', reduced_mds.shape)\n",
    "    return reduced_tsne, reduced_mds, target_embs_for_pats_labels, target_embs_for_pats_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# milestone_reduced_tsne, milestone_reduced_mds, milestone_labels, milestone_uniq_idx = get_reduced_embs(patterns, 'basis 5, kb basis 11', milestone_data, True)\n",
    "\n",
    "# baseline_reduced_tsne, baseline_reduced_mds, baseline_labels, baseline_uniq_idx = get_reduced_embs(patterns, 'basis 1, kb basis 1', baseline_data, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_font_size(small, medium, large):\n",
    "    SMALL_SIZE = small\n",
    "    MEDIUM_SIZE = medium\n",
    "    BIGGER_SIZE = large\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basis_and_eps(patterns, \\\n",
    "                       is_kb, \\\n",
    "                       reduced, \\\n",
    "                       target_embs_for_pats_labels, \\\n",
    "                       target_embs_for_pats_idx_uniq, \\\n",
    "                       figsize, \\\n",
    "                       n_basis, \\\n",
    "                       n_basis_kb, \\\n",
    "                       colors, \\\n",
    "                       file, \\\n",
    "                       label, \\\n",
    "                       has_ep_labels,\\\n",
    "                       eps_to_label=None,\\\n",
    "                       markersize=60,\n",
    "                       expand_points=(1.25, 1.5),\\\n",
    "                       force_points=(1.2, 1.2)\n",
    "                      ):\n",
    "    plt.figure(figsize=figsize)\n",
    "    set_font_size(15, 15, 15)\n",
    "    \n",
    "    start = 0\n",
    "    for i, pat in enumerate(patterns):    \n",
    "        blen = n_basis_kb if is_kb[i] else n_basis        \n",
    "        plt.scatter(x=reduced[start:start+n_basis_kb, 0][:blen], \\\n",
    "                    y=reduced[start:start+n_basis_kb, 1][:blen], \\\n",
    "                    color=colors[i], marker='o', s=markersize,\\\n",
    "                    label=patterns[i][:-6].replace('$', '\\$'))\n",
    "        start += n_basis_kb\n",
    "    \n",
    "    eps_to_label = set() if eps_to_label is None else set(eps_to_label)\n",
    "    target_embs_for_pats_labels_uniq = np.take(target_embs_for_pats_labels, \\\n",
    "                                               target_embs_for_pats_idx_uniq)\n",
    "    \n",
    "    indices = [i for i in range(len(target_embs_for_pats_labels_uniq)) \\\n",
    "               if target_embs_for_pats_labels_uniq[i] in eps_to_label]\n",
    "    if len(indices) == 0:\n",
    "        indices = list(range(len(target_embs_for_pats_labels_uniq)))\n",
    "    pruned_eps = np.array([tuple(ep) for ep in np.take(reduced[start:], indices, axis=0)], \\\n",
    "                          dtype=[('x', np.float), ('y', np.float)])\n",
    "    pruned_labels = np.take(target_embs_for_pats_labels_uniq, indices, axis=0)\n",
    "    sorted_indices = np.argsort(pruned_eps, axis=0, order=['y', 'x'])    \n",
    "    plt.scatter(x=pruned_eps['x'], y=pruned_eps['y'], color='purple', \\\n",
    "                marker='x', s=markersize, label='Entity Pairs')\n",
    "    print(\"Number of pruned entity pairs\", len(pruned_eps))\n",
    "    \n",
    "    print(eps_to_label.difference(set(pruned_labels)))\n",
    "    \n",
    "    if has_ep_labels:\n",
    "        simplifyText = lambda s: s[len(\"E_SLUG_\"):-len(\"_langEN\")].replace('_', ' ') \\\n",
    "        if s.startswith(\"E_SLUG_\") and s.endswith(\"_langEN\") else s\n",
    "        texts = []\n",
    "        for index in sorted_indices:\n",
    "            point = pruned_eps[index]            \n",
    "            \n",
    "            text = '(\"' + '\", \"'.join(list(map(simplifyText, pruned_labels[index].split('\\t')))) + '\")'\n",
    "            texts.append(plt.text(point[0], point[1], text))            \n",
    "        adjust_text(texts, expand_points=expand_points, force_points=force_points,\\\n",
    "#                     expand_text=(1.2, 1.5), expand_points=(1, 1.5), \\\n",
    "#                     force_text=(0.5, 1.2), force_points=(1.2, 1.2), \\\n",
    "                    arrowprops=dict(arrowstyle=\"-|>\", color='teal', lw=0.8),\\\n",
    "                    save_steps=False)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(label)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestone_eps_to_plot = [\n",
    "    \"Caltech\\tPasadena , California\",\\\n",
    "    \"Soochow University\\tTaipei City\",\\\n",
    "    \"Martin Schempp\\tStuttgart\",\\\n",
    "    \"Paul Dini\\tNew York City\",\\\n",
    "    \"E_SLUG_International_Olympic_Committee_langEN\\t2007\",\\\n",
    "    \"E_SLUG_Marc_Ravalomanana_langEN\\t2002\",\\\n",
    "    \"Tenzing Norgay\\t1986\",\\\n",
    "    \"Coretta Scott King\\tJanuary 2006\",\\\n",
    "    \"Interlake High School\\tBellevue\",\\\n",
    "    \"Southern High School\\tDurham\",\\\n",
    "    \"Eastern Kentucky University\\tRichmond\",\\\n",
    "    \"Oakland University\\tRochester , Michigan\",\\\n",
    "    \"World Tourism Organization\\tMadrid\",\\\n",
    "    \"E_SLUG_Lockheed_Martin_langEN\\tBethesda\",\\\n",
    "    \"Iomega\\tSan Diego\",\\\n",
    "    \"McDonald's\\tOak Brook\",\\\n",
    "    \"Gallas\\tArsenal\",\\\n",
    "    \"Malouda\\tChelsea\",\\\n",
    "    \"Kolo Toure\\tArsenal\",\\\n",
    "    \"Arsenal\\tEnglish Premier League\",\\\n",
    "    \"Stephen Roach\\tMorgan Stanley\",\\\n",
    "    \"Commodore Voreqe Bainimarama\\tE_SLUG_Fiji_langEN\",\\\n",
    "    \"Derek Abbott\\tUniversity of Adelaide\",\\\n",
    "    \"Robert F. Goheen\\tPrinceton University\",\\\n",
    "    \"E_SLUG_Arabinda_Rajkhowa_langEN\\tE_SLUG_United_Liberation_Front_of_Assam_langEN\"\\\n",
    "]\n",
    "\n",
    "baseline_eps_to_plot = [\n",
    "    \"E_SLUG_Bowe_Bergdahl_langEN\\tE_SLUG_United_States_langEN\",\\\n",
    "    \"Interlake High School\\tBellevue\",\\\n",
    "    \"Southern High School\\tDurham\",\\\n",
    "    \"IOC\\tLausanne\",\\\n",
    "    \"Samsung\\tSeoul\",\\\n",
    "    \"Peter Moore\\tBritish Embassy\"\\\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random seed: 32\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 64\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 128\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 256\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 512\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 1024\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 2048\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 4096\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 8192\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n",
      "\n",
      "Random seed: 16384\n",
      "\n",
      "Basis predictions: (44, 100)\n",
      "Unique entity pairs: (64, 100)\n",
      "Combined: (108, 100)\n",
      "Reduced: tsne-: (108, 2) mds-: (108, 2)\n",
      "Basis predictions: (4, 100)\n",
      "Unique entity pairs: (15, 100)\n",
      "Combined: (19, 100)\n",
      "Reduced: tsne-: (19, 2) mds-: (19, 2)\n",
      "Number of pruned entity pairs 25\n",
      "set()\n",
      "Number of pruned entity pairs 6\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "imgdir = os.path.join(current_dir, 'figs')\n",
    "if not os.path.exists(imgdir):\n",
    "    os.makedirs(imgdir)\n",
    "random_seeds = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
    "for random_seed in random_seeds:\n",
    "    print(\"\\nRandom seed: {}\\n\".format(random_seed))    \n",
    "    \n",
    "    _, milestone_reduced_mds, milestone_labels, milestone_uniq_idx = \\\n",
    "    get_reduced_embs(patterns, 'basis 5, kb basis 11', milestone_data, use_random=True, seed=random_seed)\n",
    "\n",
    "    _, baseline_reduced_mds, baseline_labels, baseline_uniq_idx = \\\n",
    "    get_reduced_embs(patterns, 'basis 1, kb basis 1', baseline_data, use_random=True, seed=random_seed)\n",
    "    \n",
    "    milestone_file = os.path.join(imgdir, 'milestone_mds_with_eplabels_{}.pdf'.format(random_seed))\n",
    "    plot_basis_and_eps(patterns, [False, False, True, False], milestone_reduced_mds, milestone_labels, \\\n",
    "                   milestone_uniq_idx, (18, 12), 5, 11,['r', 'g', 'b', 'orange'], \\\n",
    "                   milestone_file, 'Pattern Basis=5, KB Relation Basis=11', \\\n",
    "                   True, eps_to_label=milestone_eps_to_plot)\n",
    "    baseline_file = os.path.join(imgdir, 'baseline_mds_with_eplabels_{}.pdf'.format(random_seed))\n",
    "    plot_basis_and_eps(patterns, [False, False, True, False], baseline_reduced_mds, baseline_labels, \\\n",
    "                   baseline_uniq_idx, (12, 10), 1, 1, \\\n",
    "                   ['r', 'g', 'b', 'orange'], baseline_file, \\\n",
    "                   'Pattern Basis=1, KB Relation Basis=1', True, eps_to_label=baseline_eps_to_plot,\\\n",
    "                      expand_points=(1.25, 1.5), force_points=(1.2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_basis_and_eps(patterns, [False, False, True, False], milestone_reduced_mds, milestone_labels, \\\n",
    "#                    milestone_uniq_idx, (20, 15), 5, 11,['r', 'g', 'b', 'orange'], \\\n",
    "#                    'milestone_mds_with_eplabels.png', 'b5kb11-mds-with-eplabels', \\\n",
    "#                    True, eps_to_label=milestone_eps_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_basis_and_eps(patterns, [False, False, True, False], milestone_reduced_mds, milestone_labels, \\\n",
    "#                    milestone_uniq_idx, (20, 15), 5, 11, \\\n",
    "#                    ['r', 'g', 'b', 'orange'], 'milestone_mds_without_eplabels.png', \\\n",
    "#                    'b5kb11-mds-without-eplabels', False, eps_to_label=milestone_eps_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_basis_and_eps(patterns, [False, False, True, False], baseline_reduced_mds, baseline_labels, \\\n",
    "#                    baseline_uniq_idx, (20, 15), 1, 1, \\\n",
    "#                    ['r', 'g', 'b', 'orange'], 'baseline_mds_with_eplabels.png', \\\n",
    "#                    'b1kb1-mds-with-eplabels', True, eps_to_label=baseline_eps_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_basis_and_eps(patterns, [False, False, True, False], milestone_reduced_tsne, milestone_labels, milestone_uniq_idx, (9, 8), 5, 11, \\\n",
    "#                    ['r', 'g', 'b', 'orange'], 'milestone_tsne_with_eplabels.png', \\\n",
    "#                    'b5kb11-tsne-with-eplabels', True, label_every=1, eps_to_label=milestone_eps_to_plot)\n",
    "\n",
    "# plot_basis_and_eps(patterns, [False, False, True, False], milestone_reduced_tsne, milestone_labels, milestone_uniq_idx, (9, 8), 5, 11, \\\n",
    "#                    ['r', 'g', 'b', 'orange'], 'milestone_tsne_without_eplabels.png', \\\n",
    "#                    'b5kb11-tsne-without-eplabels', False, label_every=1, eps_to_label=milestone_eps_to_plot)\n",
    "\n",
    "# plot_basis_and_eps(patterns, [False, False, True, False], baseline_reduced_tsne, baseline_labels, \\\n",
    "#                    baseline_uniq_idx, (18, 12), 1, 1, \\\n",
    "#                    ['r', 'g', 'b', 'orange'], 'baseline_tsne_with_eplabels.png', \\\n",
    "#                    'b1kb1-tsne-with-eplabels', True, eps_to_label=baseline_eps_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
